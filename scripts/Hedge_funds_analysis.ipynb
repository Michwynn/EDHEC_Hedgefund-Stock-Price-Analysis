{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run ./Config.ipynb # run this cell only once\n",
    "%run ./Clean.ipynb # run this cell only once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fund = os.path.dirname(os.getcwd())\n",
    "raw_hedge_funds = pd.read_csv(os.path.join(path_fund, \"data/edhec-risk-hedgefunds.csv\"), delimiter = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box & Whiskers Chart for Risk Profile Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_box_whiskers(df):\n",
    "    \n",
    "    #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # transforming the data and performing the necessary statistical calculations\n",
    "    \n",
    "    lst_of_funds = [] # intialise a list\n",
    "    for var in df.fund.unique():\n",
    "        \n",
    "        data = df[df['fund'] == var]\n",
    "        fund_mean = data['return'].mean() # mean calculation\n",
    "        fund_se = stats.sem(data['return']) # standard error calculation\n",
    "\n",
    "        lower_95, upper_95 = stats.t.interval(alpha = 0.95, \n",
    "                                              df = len(data)-1,  # degrees of freedom - 1\n",
    "                                              loc = fund_mean, \n",
    "                                              scale = fund_se)\n",
    "\n",
    "        lower_66, upper_66 = stats.t.interval(alpha = 0.66666, \n",
    "                                              df = len(data)-1,  # degrees of freedom - 1\n",
    "                                              loc = fund_mean, \n",
    "                                              scale = fund_se)\n",
    "\n",
    "        lst_of_funds.append([var, fund_mean, fund_se, lower_95, upper_95, lower_66, upper_66]) # append all to list\n",
    "\n",
    "    df = pd.DataFrame.from_records(lst_of_funds)\n",
    "    df.columns = ['fund', 'mean', 'se', 'lower_95', 'upper_95', 'lower_66', 'upper_66']\n",
    "        \n",
    "    #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    # create altair charts\n",
    "    \n",
    "    base = alt.Chart(df, title = 'Historical returns (%) of funds').mark_point(\n",
    "        color = 'red',\n",
    "        size = 30,\n",
    "        filled = True).encode(\n",
    "        x = alt.X(\"mean:Q\", \n",
    "                  title = 'Historical returns, mean, 95% & 66% lower/upper intervals', \n",
    "                  scale = {\"domain\":[-0.8,2]}),\n",
    "        y = alt.Y(\"fund:N\"))\n",
    "    \n",
    "    line = alt.Chart(df).mark_bar(color ='red',size = 3).encode(\n",
    "        x = 'lower_95', \n",
    "        x2 = 'upper_95',\n",
    "        y = alt.Y(\"fund:N\"))\n",
    "    \n",
    "    bar = alt.Chart(df).mark_bar(color = 'black', size = 12).encode(\n",
    "        x = 'lower_66',\n",
    "        x2 = 'upper_66',\n",
    "        y = alt.Y(\"fund:N\"))\n",
    "    \n",
    "    mean = alt.Chart(df).mark_point(color = 'white', size = 80, filled = True).encode(\n",
    "        x = alt.X('mean:Q'),\n",
    "        y = alt.Y(\"fund:N\"))\n",
    "    \n",
    "    return (base + line + bar + mean).properties(height = 500, width = 780) # layer charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alt_box_whiskers(clean_funds(raw_hedge_funds)) #uncomment to see chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed risk assessment for each fund [eg: Volatility, skewness, kurtosis, sharpe_ratio, Value-at-Risk (VaR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_assessment(df):\n",
    "    \n",
    "    val = [] # initialise a list\n",
    "    \n",
    "    for var in df.fund.unique():\n",
    "        \n",
    "        data = df[df['fund'] == var]\n",
    "        # mean\n",
    "        mean = data['return'].mean()\n",
    "        # daily standard deviation\n",
    "        std_dev = data['return'].std()\n",
    "        # coefficient of variation\n",
    "        CV = mean/std_dev\n",
    "        # sharpe_ratio calc\n",
    "        sharpe_ratio = (mean - risk_free_rate)/std_dev # (mean-riskfree)/std\n",
    "        # kurtosis calc\n",
    "        kurto = kurtosis(data['return'].values)\n",
    "        # skewness calc\n",
    "        skewness = skew(data['return'].values)\n",
    "        # Value-at-risk calc - using point percentile function\n",
    "        VaR_90 = norm.ppf(1 - 0.9, mean, std_dev)\n",
    "        VaR_95 = norm.ppf(1 - 0.95, mean, std_dev)\n",
    "        VaR_99 = norm.ppf(1 - 0.99, mean, std_dev)\n",
    "        # min/max\n",
    "        historical_min = data['return'].min()\n",
    "        historical_max = data['return'].max()\n",
    "        # append into list\n",
    "        val.append([var, historical_min, historical_max, \n",
    "                    mean, std_dev, CV, \n",
    "                    skewness, kurto, sharpe_ratio, \n",
    "                    VaR_90, VaR_95, VaR_99])\n",
    "        \n",
    "    df = pd.DataFrame.from_records(val)\n",
    "    df.columns = ['fund','historical min', 'historical max', \n",
    "                  'mean', 'daily volatility', 'Coefficient_Variation',\n",
    "                  'skewness','kurtosis', 'daily sharpe_ratio', \n",
    "                  'VaR_90', 'VaR_95', 'VaR_99']\n",
    "    \n",
    "    return df.set_index('fund')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_stats_df = risk_assessment(clean_funds(raw_hedge_funds))\n",
    "#risk_stats_df #uncomment to see output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Locally Weighted Scatterplot Smoothing (LOWESS) algorithm\n",
    "- Apply best estimate to get a more smooth line to understand the trend\n",
    "- Adding confidence interval bands to assess volatility and perform outlier detection \n",
    "- Pairing with probability density plot for distribution assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowness_density_charts(df):\n",
    "    \n",
    "    charts = []\n",
    "    for var in df.fund.unique():\n",
    "        data = df[df['fund'] == var]\n",
    "        x = data['date'] #time values are plotted on the x-axis\n",
    "        y = data['return'] #the dependent variable (approve) is plotted on the y-axis\n",
    "        \n",
    "        min_ = -15\n",
    "        max_ = 25\n",
    "        \n",
    "        # Using the Lowess Smoother function in Tsmoothie to build the Lowess model. \n",
    "        # A key parameter is smooth_fraction, which co\n",
    "        # how responsive the model is to changes in the data. For example, \n",
    "        # if the fraction is 1.0, the LOWESS model will fit a st\n",
    "        # line (like linear regression). The closer the fraction is to 0, \n",
    "        # the more that LOWESS model follows individual data point\n",
    "\n",
    "        smoother = LowessSmoother(smooth_fraction = 0.05, iterations = 5)\n",
    "        smoother.smooth(y)\n",
    "\n",
    "        # The follow defines the uncertainty band associated with the LOWESS model. You have several options, including\n",
    "        # confidence_interval, prediction_interval, sigma_interval, and kalman_interval\n",
    "        lower_band, upper_band = smoother.get_intervals('prediction_interval')\n",
    "        data['lower_band'] = lower_band.T\n",
    "        data['upper_band'] = upper_band.T\n",
    "        data['smooth_estimate'] = smoother.smooth_data[0].T\n",
    "        \n",
    "        #++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "        # create altair charts\n",
    "        # we will vconcat 2 charts - smoother line chart with probability density chart for each fund\n",
    "        \n",
    "        # First - smoother line chart\n",
    "\n",
    "        band = alt.Chart(data, title = 'Volatility surrounding' + ' ' + var + ' ' + 'fund').mark_area(\n",
    "            color = '#009f29').encode(\n",
    "            x = alt.X('date:T', title = 'PERIOD'),\n",
    "            y = alt.Y('lower_band:Q',\n",
    "                      scale = alt.Scale(domain = [min_,max_])),\n",
    "            y2 ='upper_band:Q',\n",
    "            opacity = alt.value(0.2))\n",
    "\n",
    "        line = alt.Chart(data).mark_line(color = 'red').encode(\n",
    "            x = alt.X('date:T', title = 'PERIOD'),\n",
    "            y = alt.Y('smooth_estimate', \n",
    "                      scale = alt.Scale(domain = [min_,max_]),\n",
    "                      title = 'RETURNS'))\n",
    "\n",
    "        point = alt.Chart(data).mark_point(color = 'black', filled = True).encode(\n",
    "            x = alt.X('date:T', title = 'PERIOD'),\n",
    "            y = alt.Y('return:Q', title = 'RETURNS',\n",
    "                      scale = alt.Scale(domain = [min_,max_])))\n",
    "        \n",
    "        smoother_chart = (band + point + line) # combine all 3 charts\n",
    "        \n",
    "        \n",
    "        # second - probability density chart\n",
    "        \n",
    "        prob_dens_chart = alt.Chart(data, title = 'Probability Density of' + ' ' + var + ' ' + 'fund').transform_density(\n",
    "            'return', as_ = ['RETURNS', 'DENSITY']).mark_area(color = 'lightgrey').encode(\n",
    "            x = \"RETURNS:Q\",\n",
    "            y = 'DENSITY:Q')\n",
    "        \n",
    "        combined = alt.hconcat(smoother_chart, prob_dens_chart) #horizontal concat both charts\n",
    "        \n",
    "        charts.append(combined)\n",
    "        \n",
    "    return alt.vconcat(*charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowness_density_visuals = lowness_density_charts(clean_funds(raw_hedge_funds))\n",
    "#lowness_density_visuals #uncomment to see output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-SNE to cluster funds based on historical returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_sne(df):\n",
    "    \n",
    "    df = df.pivot(index = \"fund\", columns=\"date\", values=\"return\").dropna() #convert to wide format\n",
    "\n",
    "    return_movements = df.values # return values\n",
    "    fund = df.index # fund values\n",
    "    \n",
    "    # sklearn’s normalize with its default settings to convert all the individual values \n",
    "    # of the fund movements into the same scale\n",
    "    normalized_return_movements = normalize(return_movements)\n",
    "\n",
    "    # learning rate of 10 applied\n",
    "    TSNE_model = TSNE(learning_rate = learning_tsne_rate)\n",
    "\n",
    "    # apply the model to the array we normalized via the .fit_transform() method and \n",
    "    # we’ll create arrays from the resulting features which will constitute the X and Y coordinates from our scatter plot\n",
    "    TSNE_features = TSNE_model.fit_transform(normalized_return_movements)\n",
    "\n",
    "    # constitute the X and Y coordinates from our scatter plot\n",
    "    X = TSNE_features[:,0]\n",
    "    Y = TSNE_features[:,1]\n",
    "    \n",
    "    # Create altair scatterplot to T-SNE visualisation\n",
    "    #+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    \n",
    "    data = pd.DataFrame({'fund': fund, 'x': X, 'y': Y})\n",
    "    min_x, max_x = data['x'].min(), data['x'].max()\n",
    "    min_y, max_y = data['y'].min(), data['y'].max()\n",
    "\n",
    "    base = alt.Chart(data).mark_point(filled = True, size = 120).encode(\n",
    "        x = alt.X('x:Q', \n",
    "                  scale = alt.Scale(domain = [min_x,max_x]),\n",
    "                 axis = alt.Axis(grid=False)),\n",
    "        y = alt.Y('y:Q',\n",
    "                  scale = alt.Scale(domain = [min_y,max_y]),\n",
    "                  axis = alt.Axis(grid=False)),\n",
    "        color = alt.Color('fund:N', legend=None))\n",
    "\n",
    "    annotation = alt.Chart(data).mark_text(\n",
    "        align='left', baseline='middle', fontSize = 12, dx = 7).encode(\n",
    "        x='x:Q', y='y:Q', text='fund:N')\n",
    "\n",
    "    chart = (base + annotation).properties(height = 300, width = 780)\n",
    "                \n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_sne(clean_funds(raw_hedge_funds)) #uncomment to see output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
